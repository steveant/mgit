name: Build & Release

on:
  push:
    tags:
      - 'v*'
    branches: [ main, develop ]
    paths:
      - 'mgit/**'
      - 'Dockerfile*'
      - 'docker/**'
      - 'pyproject.toml'
      - 'requirements.txt'
      - '.github/workflows/release.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'mgit/**'
      - 'Dockerfile*'
      - 'docker/**'
  schedule:
    # Rebuild images weekly on Sundays at 3 AM UTC for security updates
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      platforms:
        description: 'Target platforms (comma-separated)'
        required: false
        default: 'linux/amd64,linux/arm64'
      push_image:
        description: 'Push image to registry'
        required: false
        type: boolean
        default: true

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  determine-build-type:
    name: Determine Build Type
    runs-on: ubuntu-latest
    outputs:
      is-release: ${{ steps.check.outputs.is-release }}
      is-development: ${{ steps.check.outputs.is-development }}
      is-pr: ${{ steps.check.outputs.is-pr }}
      is-scheduled: ${{ steps.check.outputs.is-scheduled }}
      docker-matrix: ${{ steps.matrix.outputs.matrix }}
      
    steps:
    - name: Check build type
      id: check
      run: |
        echo "is-release=${{ startsWith(github.ref, 'refs/tags/') }}" >> $GITHUB_OUTPUT
        echo "is-development=${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' }}" >> $GITHUB_OUTPUT
        echo "is-pr=${{ github.event_name == 'pull_request' }}" >> $GITHUB_OUTPUT
        echo "is-scheduled=${{ github.event_name == 'schedule' }}" >> $GITHUB_OUTPUT
        
    - name: Generate Docker build matrix
      id: matrix
      run: |
        # Define build variants for Docker (only standard for now since alpine doesn't exist)
        MATRIX=$(cat << 'EOF'
        {
          "include": [
            {
              "variant": "standard",
              "dockerfile": "Dockerfile",
              "tags": ["latest", "standard"],
              "platforms": "linux/amd64,linux/arm64"
            }
          ]
        }
        EOF
        )
        
        echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event_name != 'schedule'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run Dockerfile security scan
      uses: hadolint/hadolint-action@v3.1.0
      with:
        dockerfile: Dockerfile
        format: sarif
        output-file: hadolint-results.sarif
        
    - name: Upload Hadolint results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: hadolint-results.sarif
        
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  generate-release-notes:
    name: Generate AI Release Notes
    runs-on: ubuntu-latest
    needs: determine-build-type
    if: needs.determine-build-type.outputs.is-release == 'true'
    permissions:
      contents: read
      pull-requests: read
    outputs:
      release-notes-path: ${{ steps.save-notes.outputs.path }}
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Generate Codebase Context
      run: |
        # Create a structured overview of the codebase
        cat > generate_context.py << 'EOF'
        import os
        import ast
        import json
        from pathlib import Path
        
        def extract_docstrings(filepath):
            """Extract module, class, and function docstrings."""
            try:
                with open(filepath, 'r') as f:
                    tree = ast.parse(f.read())
                
                docstrings = []
                
                # Module docstring
                if ast.get_docstring(tree):
                    docstrings.append(f"Module: {ast.get_docstring(tree)[:200]}...")
                
                # Class and function docstrings
                for node in ast.walk(tree):
                    if isinstance(node, (ast.ClassDef, ast.FunctionDef)):
                        docstring = ast.get_docstring(node)
                        if docstring:
                            docstrings.append(f"{node.name}: {docstring[:100]}...")
                            
                return docstrings
            except:
                return []
        
        # Generate context document
        context = []
        
        # 1. Project Overview from README
        context.append("# mgit Project Overview\\n")
        with open('README.md', 'r') as f:
            lines = f.readlines()
            for i, line in enumerate(lines[:50]):  # First 50 lines
                if line.startswith('#'):
                    context.append(line)
                elif 'clone' in line.lower() or 'pull' in line.lower() or 'repository' in line.lower():
                    context.append(line)
        
        # 2. Architecture Overview
        context.append("\\n## Architecture\\n")
        context.append("```")
        os.system("tree -I '__pycache__|*.pyc|.git|dist|build' --dirsfirst -L 3 mgit/ > tree.txt")
        with open('tree.txt', 'r') as f:
            context.append(f.read())
        context.append("```\\n")
        
        # 3. Key Module Documentation
        context.append("\\n## Key Modules and Their Purpose\\n")
        
        key_files = [
            'mgit/__init__.py',
            'mgit/providers/base.py',
            'mgit/commands/listing.py',
            'mgit/config/yaml_manager.py',
            'mgit/providers/manager_v2.py'
        ]
        
        for filepath in key_files:
            if Path(filepath).exists():
                context.append(f"\\n### {filepath}\\n")
                docstrings = extract_docstrings(filepath)
                for doc in docstrings[:5]:  # First 5 docstrings
                    context.append(f"- {doc}\\n")
        
        # 4. Current Features List
        context.append("\\n## Current Features\\n")
        context.append("- Multi-provider support: Azure DevOps, GitHub, BitBucket\\n")
        context.append("- Repository discovery with query patterns\\n")
        context.append("- Bulk clone and pull operations\\n")
        context.append("- YAML-based configuration management\\n")
        context.append("- Progress tracking for operations\\n")
        
        # Save context
        with open('codebase-context.md', 'w') as f:
            f.writelines(context)
            
        print(f"Generated context document with {len(context)} lines")
        EOF
        
        python generate_context.py
        
    - name: Analyze Changes with PR Context
      env:
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        VERSION="${GITHUB_REF_NAME}"
        
        # Get last release tag
        LAST_TAG=$(git describe --tags --abbrev=0 HEAD~1 2>/dev/null || echo "")
        
        # Create comprehensive change analysis
        cat > analyze_changes.py << 'EOF'
        import subprocess
        import json
        import re
        
        last_tag = "$LAST_TAG"
        version = "$VERSION"
        
        # 1. Get merged PRs with full context
        pr_data = subprocess.run([
            "gh", "pr", "list", 
            "--state", "merged", 
            "--base", "main", 
            "--limit", "20",
            "--json", "number,title,body,author,files,labels"
        ], capture_output=True, text=True)
        
        prs = json.loads(pr_data.stdout) if pr_data.returncode == 0 else []
        
        # 2. Analyze which parts of codebase were touched
        changes = {
            "providers": [],
            "commands": [],
            "config": [],
            "core": [],
            "docs": []
        }
        
        for pr in prs:
            for file in pr.get("files", []):
                if "providers/" in file:
                    changes["providers"].append(pr["title"])
                elif "commands/" in file:
                    changes["commands"].append(pr["title"])
                elif "config/" in file:
                    changes["config"].append(pr["title"])
                elif "mgit/" in file:
                    changes["core"].append(pr["title"])
                elif ".md" in file:
                    changes["docs"].append(pr["title"])
        
        # 3. Create structured change document
        with open("structured-changes.json", "w") as f:
            json.dump({
                "pull_requests": prs,
                "categorized_changes": changes,
                "version": version
            }, f, indent=2)
            
        # 4. Extract key improvements from PR bodies
        improvements = []
        for pr in prs:
            body = pr.get("body", "")
            if body:
                # Look for improvement patterns
                if "fix" in body.lower():
                    improvements.append(f"Fixed: {pr['title']}")
                elif "add" in body.lower() or "feature" in body.lower():
                    improvements.append(f"Added: {pr['title']}")
                elif "improve" in body.lower() or "enhance" in body.lower():
                    improvements.append(f"Enhanced: {pr['title']}")
        
        with open("key-improvements.txt", "w") as f:
            f.write("\\n".join(improvements))
        EOF
        
        python analyze_changes.py
        
    - name: Generate AI Release Notes
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        pip install openai
        
        cat > generate_release_notes.py << 'EOF'
        import openai
        import json
        from pathlib import Path
        
        client = openai.OpenAI()
        
        # Load all context
        codebase_context = Path("codebase-context.md").read_text()
        structured_changes = json.loads(Path("structured-changes.json").read_text())
        key_improvements = Path("key-improvements.txt").read_text() if Path("key-improvements.txt").exists() else ""
        
        # Enhanced system prompt with your custom style
        system_prompt = f"""You are a technical writer creating release notes for mgit with a touch of personality.
        
        CODEBASE CONTEXT:
        {codebase_context}
        
        CRITICAL RULES:
        - mgit is ONLY for managing git repositories (clone, pull, list)
        - Never mention CI/CD, pipelines, or automation features
        - Focus on actual repository management improvements
        - Be factual and specific about changes
        - Include a few 80s pop culture references throughout the releases and always end with a quote
        - Keep the reference light and professional
        
        GOOD 80s pop culture TOUCHES (use sparingly):
        - movie references
        - music references
        - sitcom references
        - games (video and other)
        - commercials and pop culture
        """
        
        # User prompt with structured changes
        user_prompt = f"""Generate release notes for mgit {structured_changes['version']}.
        
        CHANGES BY CATEGORY:
        - Provider improvements: {len(structured_changes['categorized_changes']['providers'])} changes
        - Command updates: {len(structured_changes['categorized_changes']['commands'])} changes  
        - Config changes: {len(structured_changes['categorized_changes']['config'])} changes
        - Core updates: {len(structured_changes['categorized_changes']['core'])} changes
        
        KEY IMPROVEMENTS:
        {key_improvements}
        
        PULL REQUESTS:
        {json.dumps(structured_changes['pull_requests'], indent=2)}
        
        Create clear, accurate release notes that explain what changed and why it matters for users managing multiple git repositories.
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,
            max_tokens=1500
        )
        
        release_notes = response.choices[0].message.content
        
        # Save release notes
        version = structured_changes['version']
        filename = f"RELEASE_NOTES_{version}.md"
        Path(filename).write_text(release_notes)
        
        print(f"Generated release notes: {filename}")
        print(f"Length: {len(release_notes)} characters")
        EOF
        
        python generate_release_notes.py || echo "# mgit ${GITHUB_REF_NAME}\\n\\nRelease notes generation failed. See commit history for changes." > RELEASE_NOTES_${GITHUB_REF_NAME}.md
        
    - name: Save release notes path
      id: save-notes
      run: |
        echo "path=RELEASE_NOTES_${GITHUB_REF_NAME}.md" >> $GITHUB_OUTPUT
        
    - name: Upload release notes artifact
      uses: actions/upload-artifact@v4
      with:
        name: release-notes
        path: RELEASE_NOTES_*.md
        retention-days: 1

  build-docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [determine-build-type, security-scan]
    if: always() && (needs.security-scan.result == 'success' || needs.security-scan.result == 'skipped')
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.determine-build-type.outputs.docker-matrix) }}
    permissions:
      contents: read
      packages: write
      security-events: write
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up QEMU
      uses: docker/setup-qemu-action@v3
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Log in to Container Registry
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        flavor: |
          latest=false
          suffix=-${{ matrix.variant }},onlatest=true
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=raw,value=latest,enable={{is_default_branch}},suffix=
          type=raw,value=${{ join(matrix.tags, ',') }},enable={{is_default_branch}}
        labels: |
          org.opencontainers.image.title=mgit (${{ matrix.variant }})
          org.opencontainers.image.description=Multi-provider Git management tool (${{ matrix.variant }} variant)
          
    - name: Determine platforms
      id: platforms
      run: |
        if [ "${{ github.event_name }}" = "pull_request" ]; then
          echo "platforms=linux/amd64" >> $GITHUB_OUTPUT
        else
          echo "platforms=${{ github.event.inputs.platforms || matrix.platforms }}" >> $GITHUB_OUTPUT
        fi
        
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      id: build
      with:
        context: .
        file: ./${{ matrix.dockerfile }}
        platforms: ${{ steps.platforms.outputs.platforms }}
        push: ${{ github.event_name != 'pull_request' && (github.event.inputs.push_image != 'false') }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha,scope=${{ matrix.variant }}
        cache-to: type=gha,mode=max,scope=${{ matrix.variant }}
        build-args: |
          MGIT_VERSION=${{ github.ref_name }}
          BUILD_DATE=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.created'] }}
          VCS_REF=${{ github.sha }}
          
    - name: Test Docker image
      if: contains(steps.platforms.outputs.platforms, 'linux/amd64')
      run: |
        # Build local test image for amd64
        docker buildx build \
          --platform linux/amd64 \
          --file ./${{ matrix.dockerfile }} \
          --tag mgit:test-${{ matrix.variant }} \
          --load \
          --build-arg MGIT_VERSION=test \
          --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
          --build-arg VCS_REF=${{ github.sha }} \
          .
        
        # Test basic functionality
        echo "Testing basic commands..."
        docker run --rm mgit:test-${{ matrix.variant }} --version
        docker run --rm mgit:test-${{ matrix.variant }} --help
        
        # Test health check
        echo "Testing health check..."
        timeout 30s docker run --rm mgit:test-${{ matrix.variant }} /usr/local/bin/healthcheck.sh
        
        # Test entrypoint
        echo "Testing entrypoint..."
        docker run --rm mgit:test-${{ matrix.variant }} config --show || true
        
    - name: Run container security scan
      if: github.event_name != 'pull_request'
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: mgit:test-${{ matrix.variant }}
        format: 'sarif'
        output: 'trivy-image-results.sarif'
        
    - name: Upload container scan results
      if: github.event_name != 'pull_request'
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-image-results.sarif'

  build-binaries:
    name: Build Binaries
    needs: determine-build-type
    if: needs.determine-build-type.outputs.is-release == 'true'
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - os: ubuntu-latest
            platform: linux-x64
          - os: macos-latest
            platform: macos-x64
          - os: windows-latest
            platform: windows-x64
    runs-on: ${{ matrix.os }}
    permissions:
      contents: write
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build setuptools wheel
        pip install -r requirements.txt
        pip install pyinstaller
    
    - name: Build packages (Linux only)
      if: matrix.os == 'ubuntu-latest'
      run: |
        python -m build
        
    - name: Build executable
      run: |
        ${{ matrix.os == 'windows-latest' && 'pyinstaller --onefile --name mgit-${GITHUB_REF_NAME}-${{ matrix.platform }}.exe mgit/__main__.py' || format('pyinstaller --onefile --name mgit-{0}-{1} mgit/__main__.py', github.ref_name, matrix.platform) }}
        
    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ${{ matrix.platform }}-artifacts
        path: |
          dist/
        retention-days: 1

  create-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [determine-build-type, generate-release-notes, build-binaries]
    if: needs.determine-build-type.outputs.is-release == 'true'
    permissions:
      contents: write
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      
    - name: Create Release
      uses: softprops/action-gh-release@v1
      with:
        files: |
          linux-x64-artifacts/dist/*.whl
          linux-x64-artifacts/dist/*.tar.gz
          linux-x64-artifacts/dist/mgit-*-linux-x64
          macos-x64-artifacts/dist/mgit-*-macos-x64
          windows-x64-artifacts/dist/mgit-*-windows-x64.exe
        body_path: release-notes/RELEASE_NOTES_${{ github.ref_name }}.md
        draft: false
        prerelease: false
        generate_release_notes: false
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  security-report:
    name: Security Report
    runs-on: ubuntu-latest
    needs: [build-docker]
    if: always() && github.event_name != 'pull_request'
    timeout-minutes: 10
    
    steps:
    - name: Generate security summary
      run: |
        echo "# Docker Security Scan Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Image Variants Built" >> $GITHUB_STEP_SUMMARY
        echo "- Standard (Python slim-based)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Security Scans Completed" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Dockerfile linting (Hadolint)" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Filesystem vulnerability scan (Trivy)" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Container image vulnerability scan (Trivy)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Registry Information" >> $GITHUB_STEP_SUMMARY
        echo "- Registry: ${{ env.REGISTRY }}" >> $GITHUB_STEP_SUMMARY
        echo "- Repository: ${{ env.IMAGE_NAME }}" >> $GITHUB_STEP_SUMMARY
        echo "- Branch: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY

  notify:
    name: Notify Deployment
    runs-on: ubuntu-latest
    needs: [determine-build-type, build-docker]
    if: success() && needs.determine-build-type.outputs.is-development == 'true'
    
    steps:
    - name: Create deployment summary
      run: |
        echo "ðŸ³ Docker images published successfully!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Published Images" >> $GITHUB_STEP_SUMMARY
        echo "- \`${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest\`" >> $GITHUB_STEP_SUMMARY
        echo "- \`${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Usage" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
        echo "docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest" >> $GITHUB_STEP_SUMMARY
        echo "docker run --rm ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest --help" >> $GITHUB_STEP_SUMMARY
        echo "\`\`\`" >> $GITHUB_STEP_SUMMARY